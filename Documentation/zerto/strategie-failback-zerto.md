# Strat√©gie Failback Zerto - Gestion des T√¢ches CRON

**Date :** 2025-12-29
**Statut :** Proposition
**Auteur :** Analyse Technique PRA

---

## 1. Infrastructure Actuelle

### Configuration Zerto en Production

**Plateforme :**
- **H√©bergeur :** OVH Cloud
- **Hyperviseur :** VMware vSphere
- **Solution PRA :** Zerto Virtual Replication

**P√©rim√®tre de Protection :**
- **Site Primaire (RBX)** : 36 VMs prot√©g√©es
- **Site Secours (SBG)** : 16 VMs (r√©plicas + services annexes)
- **Total :** 52 VMs sous surveillance Zerto

**Performances R√©plication :**
- **RPO Moyen :** 8 secondes ‚≠ê (objectif standard : 5 minutes)
- **Mode :** Continuous Data Protection (CDP) - R√©plication de blocs en continu
- **Consistance :** Crash Consistent (par d√©faut)

### Architecture des Bases de Donn√©es

Les bases de donn√©es sont **install√©es directement sur les VMs** (non externalis√©es). Types de DB concern√©s :
- MySQL/MariaDB (applications m√©tier)
- PostgreSQL (backoffice, analytics)
- MongoDB (caching, sessions)

**Mode de r√©plication :** Crash Consistent au niveau bloc (pas de coordination applicative).

---

## 2. Analyse Technique : Crash Consistent vs Application Consistent

### Qu'est-ce que le "Crash Consistent" ?

Zerto capture les **I/O disque en continu** au niveau bloc, sans coordination avec les applications. C'est comme si :
- On coupait l'alimentation de la VM brutalement
- On red√©marrait la VM depuis le dernier snapshot (‚âà8s avant l'incident)

**Pour les bases de donn√©es, cela signifie :**
- Les donn√©es √©crites sur disque sont coh√©rentes (pas de blocs corrompus)
- Les transactions en m√©moire (buffers non flush√©s) peuvent √™tre perdues
- La DB effectue un **recovery automatique** au d√©marrage (replay des WAL/redo logs)

### Avantages du Mode Crash Consistent

‚úÖ **Performance :** Aucun overhead sur les VMs en production (pas de VSS, pas de scripts)
‚úÖ **Simplicit√© :** Pas de configuration applicative requise
‚úÖ **Compatibilit√© :** Fonctionne avec toutes les applications
‚úÖ **RPO Optimal :** 8s de perte de donn√©es maximum (excellent)

### Risques Identifi√©s pour les Bases de Donn√©es

| Risque | Impact | Probabilit√© | Mitigation |
|--------|--------|-------------|------------|
| **Perte de transactions en cours** | üü° Moyen | üü¢ Faible (8s de fen√™tre) | Acceptable pour donn√©es non critiques |
| **Temps de recovery long** | üü° Moyen | üü° Moyen (d√©pend de la charge) | Pr√©voir +2-5min au d√©marrage |
| **Incoh√©rence si op√©ration critique** | üî¥ √âlev√© | üü¢ Tr√®s faible | Monitoring des op√©rations longues (VACUUM, REINDEX) |
| **Corruption si DB mal configur√©e** | üî¥ Critique | üü¢ Tr√®s faible | ‚úÖ V√©rifier journaling activ√© (InnoDB, WAL) |

### √âvaluation par Type de DB

| Base de Donn√©es | Crash Consistent Safe ? | Justification | Recommandation |
|-----------------|:-----------------------:|---------------|----------------|
| **PostgreSQL** | ‚úÖ OUI | WAL assure la coh√©rence, recovery automatique rapide | Crash Consistent OK |
| **MySQL (InnoDB)** | ‚úÖ OUI | InnoDB log buffer + doublewrite buffer | Crash Consistent OK |
| **MySQL (MyISAM)** | ‚ö†Ô∏è RISQU√â | Pas de transactions, risque de corruption | **Migrer vers InnoDB** ou Application Consistent |
| **MongoDB** | ‚úÖ OUI | Journaling activ√© par d√©faut (WiredTiger) | Crash Consistent OK si `journal=true` |
| **Oracle** | ‚úÖ OUI | Redo logs + checkpoint automatique | Crash Consistent OK mais Application Consistent pr√©f√©rable |
| **SQL Server** | ‚úÖ OUI | Transaction log assure la coh√©rence | Crash Consistent OK |

### Quand Passer en Application Consistent ?

Envisager le mode **Application Consistent** (avec VSS/scripts) si :

‚ùå **Vous avez des DB MyISAM** (risque de corruption)
‚ùå **Op√©rations batch longues** (> 1h) qui ne doivent pas √™tre interrompues
‚ùå **Exigence RPO = 0** (aucune perte tol√©r√©e)
‚ùå **R√©glementations strictes** (finance, sant√©) n√©cessitant des recovery garanties

‚ö†Ô∏è **Inconv√©nients de l'Application Consistent :**
- Impact performance (VSS freeze les I/O temporairement)
- Complexit√© (scripts √† maintenir pour chaque DB)
- RPO d√©grad√© (snapshots toutes les 5-15min au lieu de 8s)

### Verdict pour la Configuration Actuelle

üü¢ **Crash Consistent avec RPO 8s est ADAPT√â** si :
- ‚úÖ Les DB utilisent des moteurs transactionnels (InnoDB, PostgreSQL WAL, MongoDB WiredTiger)
- ‚úÖ La perte de 8s de transactions est acceptable m√©tier
- ‚úÖ Les applications g√®rent les retry/idempotence

üî¥ **Action requise :**
- [ ] **V√©rifier** que toutes les DB MySQL utilisent InnoDB (pas MyISAM)
- [ ] **Tester** un failover r√©el pour mesurer le temps de recovery des DB
- [ ] **Documenter** le RPO m√©tier acceptable par application (8s OK ?)

---

## 3. Contexte & Probl√©matique - Gestion des CRON

### Situation Actuelle
Les applications d√©ploy√©es sur les VMs (RBX primaire, SBG secours) contiennent des **t√¢ches CRON** critiques. Lors d'un incident et du retour √† la normale, une **fen√™tre de risque** appara√Æt :

**Probl√®me identifi√© :**
- Les VMs sur RBX red√©marrent/sont accessibles **avant** la bascule DNS/applicative officielle
- Pendant cette fen√™tre, **les CRON tournent en parall√®le** sur RBX (site primaire restaur√©) ET SBG (site de secours encore actif)
- **Risque :** Traitement en double, corruption de donn√©es, incoh√©rences m√©tier

---

## 4. Processus PRA Actuel - Analyse D√©taill√©e

### 4.1 Phase 1 : D√©tection de l'Incident (RBX ‚Üí SBG)

| √âtape | Action | Responsable | Dur√©e |
|-------|--------|-------------|-------|
| **1. D√©tection** | Alerte monitoring (sonde, Zerto, supervision) d√©tecte l'indisponibilit√© RBX | Automatique / Astreinte | T+0 √† T+5min |
| **2. D√©cision Failover** | Validation de la n√©cessit√© de basculer vers SBG | Responsable Technique | T+5min √† T+15min |
| **3. Ex√©cution Failover** | Activation du VPG Zerto : bascule des VMs vers SBG | Op√©rateur / Zerto | T+15min √† T+30min |
| **4. V√©rification Sant√©** | Tests de disponibilit√© des services sur SBG (HTTP, DB, CRON) | √âquipe Ops | T+30min √† T+45min |
| **5. Bascule DNS/R√©seau** | Modification des enregistrements DNS/Load Balancer vers SBG | √âquipe R√©seau | T+45min √† T+60min |
| **6. Communication** | Notification aux √©quipes et utilisateurs | Support | T+60min |

**√âtat stable :** Les applications tournent sur SBG. RBX est hors-ligne ou en √©tat d√©grad√©.

---

### 4.2 Phase 2 : Retour √† la Normale (SBG ‚Üí RBX) - **ZONE √Ä RISQUE**

| √âtape | Action | √âtat des CRON | Risque |
|-------|--------|---------------|--------|
| **7. Restauration RBX** | VMware vSphere restaure les VMs RBX (hyperviseur, r√©seau, stockage) | ‚ùå RBX : Inactifs<br>‚úÖ SBG : Actifs | Aucun |
| **8. Synchronisation Zerto** | Zerto synchronise les donn√©es SBG ‚Üí RBX (delta depuis incident) | ‚ùå RBX : Inactifs<br>‚úÖ SBG : Actifs | Aucun |
| **9. D√©marrage VMs RBX** | ‚ö†Ô∏è **POINT CRITIQUE** : VMs RBX d√©marrent automatiquement | ‚ö†Ô∏è **RBX : ACTIFS**<br>‚úÖ SBG : Actifs | **DOUBLE EX√âCUTION** |
| **10. Validation Services RBX** | Tests applicatifs sur RBX (peut prendre 15-30min) | ‚ö†Ô∏è **RBX : ACTIFS**<br>‚úÖ SBG : Actifs | **DOUBLE EX√âCUTION** |
| **11. Failback Zerto** | Ex√©cution du failback Zerto (commit du retour vers RBX) | ‚ö†Ô∏è **RBX : ACTIFS**<br>‚úÖ SBG : Actifs | **DOUBLE EX√âCUTION** |
| **12. Bascule DNS/R√©seau** | Modification DNS/LB pour pointer vers RBX | ‚úÖ RBX : Actifs<br>‚ö†Ô∏è SBG : Encore actifs | **DOUBLE EX√âCUTION** |
| **13. Arr√™t SBG** | Arr√™t propre des VMs SBG (apr√®s validation RBX stable) | ‚úÖ RBX : Actifs<br>‚ùå SBG : Arr√™t | Fin du risque |

**Fen√™tre de risque :** Entre l'√©tape 9 et 13 (potentiellement **30 √† 60 minutes**).

---

## 5. Solutions Propos√©es

### Solution 1 : **Mode Pause VMware Automatique** (Recommand√©e)

#### Principe
Configurer les VMs RBX pour qu'elles d√©marrent en **√©tat "suspendu" (paused)** apr√®s restauration, et ne les activer qu'apr√®s validation manuelle.

#### Impl√©mentation

**A. Configuration VMware (vSphere)**
- Modifier le param√®tre de d√©marrage des VMs RBX critiques :
  - `powerOnBehavior = "suspended"` ou utiliser un script vSphere PowerCLI
  - Les VMs d√©marrent mais sont imm√©diatement mises en pause

**B. Workflow Failback R√©vis√©**
```
1. Restauration RBX ‚Üí VMs d√©marrent en mode PAUSE (CRON inactifs)
2. Synchronisation Zerto ‚Üí Donn√©es √† jour
3. Validation manuelle :
   - Tests de connectivit√© r√©seau
   - Tests de coh√©rence DB
   - V√©rification des montages NFS/Storage
4. ‚úÖ Activation manuelle des VMs RBX (resume)
5. Bascule DNS vers RBX
6. Arr√™t VMs SBG
```

**Avantages :**
- ‚úÖ Contr√¥le total, aucun CRON ne d√©marre avant validation
- ‚úÖ Pas de modification applicative
- ‚úÖ Respect des SLA (validation avant production)

**Inconv√©nients :**
- ‚ùå N√©cessite intervention manuelle (automatisable via script)
- ‚ùå D√©pend de la configuration VMware

---

### Solution 2 : **S√©maphore Applicatif avec Fichier Lock**

#### Principe
Impl√©menter un **verrou logiciel** que chaque CRON v√©rifie avant ex√©cution.

#### Impl√©mentation

**A. Fichier de configuration central**
- Cr√©er un fichier `/etc/app/pra-status.lock` sur chaque VM
- Contenu : `ACTIVE_SITE=SBG` ou `ACTIVE_SITE=RBX`

**B. Modification des CRON**
```bash
#!/bin/bash
# Exemple : /usr/local/bin/safe-cron-wrapper.sh

ACTIVE_SITE=$(cat /etc/app/pra-status.lock | grep ACTIVE_SITE | cut -d= -f2)
CURRENT_SITE=$(hostname | grep -oE 'rbx|sbg')

if [ "$ACTIVE_SITE" != "$CURRENT_SITE" ]; then
  echo "CRON bloqu√© : site actif=$ACTIVE_SITE, site actuel=$CURRENT_SITE"
  exit 0
fi

# Ex√©cuter la vraie t√¢che CRON
/usr/local/bin/ma-tache-metier.sh
```

**C. Workflow Failback R√©vis√©**
```
1. RBX d√©marre ‚Üí CRON v√©rifient /etc/app/pra-status.lock ‚Üí Trouve "SBG" ‚Üí Exit silencieux
2. Validation RBX compl√®te
3. ‚úÖ Script Ansible/SSH met √† jour pra-status.lock sur RBX : "ACTIVE_SITE=RBX"
4. Bascule DNS
5. Mise √† jour pra-status.lock sur SBG : "ACTIVE_SITE=NONE" (s√©curit√©)
6. Arr√™t SBG
```

**Avantages :**
- ‚úÖ Solution logicielle, ind√©pendante de l'hyperviseur
- ‚úÖ Tra√ßabilit√© (logs applicatifs)
- ‚úÖ Automatisable via Ansible/Chef/Puppet

**Inconv√©nients :**
- ‚ùå N√©cessite modification de **tous** les CRON
- ‚ùå Risque si le fichier lock est mal synchronis√©
- ‚ùå Maintenance (wrap chaque CRON)

---

### Solution 3 : **D√©sactivation Temporaire des CRON via Systemd Timer Override**

#### Principe
Utiliser un service systemd qui d√©sactive dynamiquement les timers CRON au boot.

#### Impl√©mentation

**A. Service Systemd "PRA Guard"**
Cr√©er `/etc/systemd/system/pra-guard.service` :
```ini
[Unit]
Description=PRA Guard - Disable CRON on Standby Site
Before=cron.service
After=network-online.target

[Service]
Type=oneshot
ExecStart=/usr/local/bin/pra-guard-check.sh
RemainAfterExit=yes

[Install]
WantedBy=multi-user.target
```

**B. Script de v√©rification**
```bash
#!/bin/bash
# /usr/local/bin/pra-guard-check.sh

CONSUL_KEY="pra/active-site"
ACTIVE_SITE=$(curl -s http://consul.local:8500/v1/kv/$CONSUL_KEY?raw)
CURRENT_SITE=$(hostname | grep -oE 'rbx|sbg')

if [ "$ACTIVE_SITE" != "$CURRENT_SITE" ]; then
  systemctl stop cron.service
  systemctl mask cron.service
  echo "CRON d√©sactiv√© : site standby"
else
  systemctl unmask cron.service
  systemctl start cron.service
  echo "CRON activ√© : site actif"
fi
```

**C. Workflow Failback R√©vis√©**
```
1. RBX d√©marre ‚Üí pra-guard.service s'ex√©cute ‚Üí Lit Consul ‚Üí CRON masqu√©
2. Validation RBX
3. ‚úÖ Mise √† jour Consul : "pra/active-site=RBX"
4. Red√©marrage pra-guard.service sur RBX ‚Üí CRON activ√©
5. Bascule DNS
6. Mise √† jour Consul ‚Üí SBG passe en standby
7. Arr√™t SBG
```

**Avantages :**
- ‚úÖ Centralis√© (pas de modification des CRON)
- ‚úÖ Utilise Consul/etcd pour √©tat distribu√©
- ‚úÖ R√©utilisable pour autres services (non seulement CRON)

**Inconv√©nients :**
- ‚ùå D√©pendance √† un service externe (Consul)
- ‚ùå Complexit√© de setup initial

---

### Solution 4 : **Orchestration Zerto avec Pre/Post Scripts**

#### Principe
Utiliser les **scripts Zerto** (Pre-failback / Post-failback) pour automatiser la d√©sactivation/activation des CRON.

#### Impl√©mentation

**A. Script Zerto Pre-Failback (C√¥t√© RBX)**
Ex√©cut√© juste avant le d√©marrage des VMs RBX :
```bash
#!/bin/bash
# Ex√©cut√© sur l'h√¥te vSphere avant boot des VMs RBX
for vm in $(zerto-cli list-vms --vpg=PROD-RBX); do
  ssh root@$vm "systemctl stop cron && touch /var/lock/pra-failback-in-progress"
done
```

**B. Script Zerto Post-Failback (Apr√®s validation)**
```bash
#!/bin/bash
# Ex√©cut√© apr√®s commit du failback
for vm in $(zerto-cli list-vms --vpg=PROD-RBX); do
  ssh root@$vm "rm /var/lock/pra-failback-in-progress && systemctl start cron"
done
```

**Avantages :**
- ‚úÖ Natif Zerto (int√©gr√© au workflow PRA)
- ‚úÖ Automatique

**Inconv√©nients :**
- ‚ùå D√©pend de la version Zerto et de la licence
- ‚ùå N√©cessite acc√®s SSH entre Zerto et VMs (s√©curit√©)

---

## 6. Matrice de Comparaison

| Crit√®re | Solution 1<br>(VMware Pause) | Solution 2<br>(Fichier Lock) | Solution 3<br>(Systemd + Consul) | Solution 4<br>(Zerto Scripts) |
|---------|:---:|:---:|:---:|:---:|
| **Complexit√©** | üü¢ Faible | üü° Moyenne | üî¥ √âlev√©e | üü° Moyenne |
| **Modification Apps** | üü¢ Aucune | üî¥ Tous les CRON | üü¢ Aucune | üü¢ Aucune |
| **Automatisation** | üü° Partielle | üü¢ Totale | üü¢ Totale | üü¢ Totale |
| **D√©pendances** | VMware API | Aucune | Consul/etcd | Zerto Scripting |
| **R√©versibilit√©** | üü¢ Imm√©diate | üü¢ Imm√©diate | üü¢ Imm√©diate | üü¢ Imm√©diate |
| **Co√ªt** | üü¢ Nul | üü¢ Nul | üü° Setup Consul | üü¢ Inclus Zerto |
| **Risque Erreur** | üü¢ Faible | üü° Moyen | üü° Moyen | üü¢ Faible |

---

## 7. Recommandation Finale

### Approche Hybride : **Solution 1 + Solution 2**

**Phase 1 (Court terme - 1 semaine) :**
- Impl√©menter **Solution 1** (VMware Pause) pour s√©curiser imm√©diatement les failbacks
- Cr√©er une proc√©dure manuelle valid√©e

**Phase 2 (Moyen terme - 1 mois) :**
- D√©ployer **Solution 2** (Fichier Lock) sur les CRON critiques
- Automatiser via Ansible/Terraform

**Pourquoi cette approche ?**
- ‚úÖ Protection imm√©diate (VMware Pause)
- ‚úÖ Redondance logicielle (Lock File) en cas d'√©chec VMware
- ‚úÖ Pas de d√©pendance externe (Consul)
- ‚úÖ Progressif (permet de tester)

---

## 8. Plan d'Action

### Sprint 1 : S√©curisation Imm√©diate (3 jours)
- [ ] Configurer les VMs RBX avec d√©marrage en mode suspendu
- [ ] Cr√©er la checklist de validation failback
- [ ] Tester sur un VPG non-critique
- [ ] Former les √©quipes Ops

### Sprint 2 : Automatisation (2 semaines)
- [ ] D√©velopper le wrapper CRON avec fichier lock
- [ ] D√©ployer sur 3 CRON pilotes
- [ ] Mesurer l'impact (logs, m√©triques)
- [ ] Rollout progressif (20% ‚Üí 50% ‚Üí 100%)

### Sprint 3 : Industrialisation (1 mois)
- [ ] Int√©grer dans l'outillage Zerto (scripts post-failback)
- [ ] Ajouter monitoring (alerte si CRON bloqu√© > 2h)
- [ ] Documenter la runbook compl√®te
- [ ] Simuler un failback en conditions r√©elles

---

## 9. M√©triques de Succ√®s

| KPI | Cible | Mesure |
|-----|-------|--------|
| Fen√™tre de double ex√©cution | 0 min | Logs CRON (timestamps) |
| Temps de failback | < 30 min | Chrono Zerto |
| Incidents de corruption de donn√©es | 0 | Tickets post-PRA |
| Conformit√© proc√©dure | 100% | Checklist valid√©e |

---

## 10. Annexes

### A. Checklist Failback (Version Manuelle)

```
‚òê 1. V√©rifier l'√©tat de r√©plication Zerto (RPO < 10s, target : 8s)
‚òê 2. Arr√™ter les CRON sur SBG (systemctl stop cron)
‚òê 3. Lancer la synchronisation finale Zerto
‚òê 4. D√©marrer les VMs RBX en mode pause (ou v√©rifier auto-pause)
‚òê 5. Reprendre les VMs RBX (resume)
‚òê 6. Tester connectivit√© r√©seau RBX (ping, curl)
‚òê 7. V√©rifier les logs de recovery des DB (PostgreSQL, MySQL, MongoDB)
    - PostgreSQL : grep "database system is ready" /var/log/postgresql/*.log
    - MySQL : grep "ready for connections" /var/log/mysql/error.log
    - MongoDB : grep "WiredTiger recovery" /var/log/mongodb/mongod.log
‚òê 8. Tester acc√®s base de donn√©es RBX (select 1, insert test)
‚òê 9. V√©rifier l'int√©grit√© des montages NFS/Volumes
‚òê 10. Lancer 1 CRON manuellement sur RBX (validation)
‚òê 11. Basculer le DNS/LB vers RBX
‚òê 12. V√©rifier absence d'erreurs (logs applicatifs)
‚òê 13. Arr√™ter les VMs SBG
‚òê 14. R√©activer la r√©plication Zerto (RBX ‚Üí SBG)
‚òê 15. Post-mortem (documenter les anomalies, temps de recovery DB)
```

### B. Commandes Utiles

#### Gestion des VMs

```bash
# Pause d'une VM via vSphere CLI
vim-cmd vmsvc/power.suspend <vmid>

# Resume d'une VM
vim-cmd vmsvc/power.on <vmid>

# Lister les VMs et leur √©tat
vim-cmd vmsvc/getallvms
```

#### Gestion des CRON

```bash
# V√©rifier l'√©tat des CRON
systemctl status cron

# Lister les CRON actifs
crontab -l
ls -la /etc/cron.d/

# V√©rifier les logs CRON
grep CRON /var/log/syslog | tail -50

# Arr√™ter temporairement les CRON
systemctl stop cron
systemctl mask cron   # Emp√™che le red√©marrage automatique
```

#### V√©rification des Bases de Donn√©es

```bash
# PostgreSQL - V√©rifier le mode recovery
psql -U postgres -c "SELECT pg_is_in_recovery();"

# PostgreSQL - V√©rifier le WAL (Write-Ahead Log)
psql -U postgres -c "SELECT pg_current_wal_lsn();"

# MySQL - V√©rifier le moteur de stockage (InnoDB recommand√©)
mysql -e "SELECT TABLE_SCHEMA, TABLE_NAME, ENGINE FROM information_schema.TABLES WHERE ENGINE='MyISAM';"

# MySQL - V√©rifier le statut InnoDB
mysql -e "SHOW ENGINE INNODB STATUS\G" | grep -A 20 "LOG"

# MongoDB - V√©rifier le journaling
mongo --eval "db.serverStatus().storageEngine.persistent"
mongo --eval "db.adminCommand({getCmdLineOpts: 1}).parsed.storage.journal.enabled"

# Temps de recovery apr√®s crash (v√©rifier les logs)
# PostgreSQL
grep "database system was interrupted" /var/log/postgresql/postgresql-*.log -A 10

# MySQL
grep "InnoDB: Starting crash recovery" /var/log/mysql/error.log -A 10

# MongoDB
grep "WiredTiger recovery" /var/log/mongodb/mongod.log -A 10
```

#### Monitoring Zerto

```bash
# V√©rifier le RPO actuel (via API Zerto si disponible)
curl -k -u admin:password https://zerto-vra:9669/v1/vpgs | jq '.[] | {name: .VpgName, rpo: .ActualRPO}'

# V√©rifier l'√©tat de r√©plication
# (remplacer par la commande sp√©cifique √† votre setup Zerto/OVH)
```

### C. Points de Vigilance - Crash Consistent

**√Ä v√©rifier imp√©rativement avant un failover :**

1. **MySQL :**
   - ‚úÖ Toutes les tables en InnoDB (pas de MyISAM)
   - ‚úÖ `innodb_flush_log_at_trx_commit = 1` (durabilit√© ACID)
   - ‚úÖ `innodb_doublewrite = ON` (protection contre corruption)

2. **PostgreSQL :**
   - ‚úÖ `fsync = on` (garantie √©criture sur disque)
   - ‚úÖ `full_page_writes = on` (protection WAL)
   - ‚úÖ Archivage WAL configur√© pour PITR (Point-In-Time Recovery)

3. **MongoDB :**
   - ‚úÖ `storage.journal.enabled = true` (obligatoire pour WiredTiger)
   - ‚úÖ `writeConcern` configur√© pour durabilit√© (w: majority)

**Commandes de validation :**

```bash
# MySQL
mysql -e "SHOW VARIABLES LIKE 'innodb_flush_log_at_trx_commit';"
mysql -e "SHOW VARIABLES LIKE 'innodb_doublewrite';"

# PostgreSQL
psql -U postgres -c "SHOW fsync;"
psql -U postgres -c "SHOW full_page_writes;"

# MongoDB
mongo --eval "db.serverCmdLineOpts().parsed.storage.journal"
```

---

**Validation requise :** Ce document doit √™tre valid√© par l'√©quipe Infra/PRA avant impl√©mentation.